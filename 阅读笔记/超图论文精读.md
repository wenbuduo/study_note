# 摘要

我们首先赋予图神经 CF 范式以通过超图转换器网络维持用户和项目之间的全局协作效果。通过提炼的全局上下文，提出了一种跨视图生成自监督学习组件，用于用户-项目交互图上的数据增强，从而增强推荐系统的鲁棒性。



## 待解决的问题

（1）直接聚合来自所有交互边缘的信息将损害准确的用户表示。更糟糕的是，多跳相邻顶点（用户或项目）之间的嵌入传播会放大噪声。

（2）数据稀疏和偏态分布问题仍然阻碍了有效的用户-项目交互建模。

## 关于图的信息传播

PinSage 和 NGCF 尝试通过捕获基于图的 CF 信号来聚合邻近信息以进行推荐。为了简化基于图的消息传递，LightGCN 在嵌入传播期间省略了繁重的非线性变换器并提高了推荐性能。

## 关于数据稀疏性

虽然存在一些最近开发的推荐方法（SGL和SLRec ）利用自监督学习来改善用户表示，但这些方法主要通过基于概率的随机掩模操作生成额外的监督信息，这可能会保持在数据增强过程中出现一些噪声交互并丢失一些重要的训练信号贡献。

## 关于图的信息传播

PinSage 和 NGCF 尝试通过捕获基于图的 CF 信号来聚合邻近信息以进行推荐。为了简化基于图的消息传递，LightGCN 在嵌入传播期间省略了繁重的非线性变换器并提高了推荐性能

## 自监督学习

DGI 和GMI 通过辅助任务在GNN框架上执行生成式自监督学习。遵循这一研究路线，HCCF  利用超图生成对比信号来改进基于图的推荐系统。与它们不同的是，这项工作通过生成式自我监督学习框架增强了基于图的协同过滤范式

# 方法

### 1.本地的图结构学习

我们提出将每个节点的相邻子图结构编码成图拓扑感知嵌入，将拓扑位置信息注入到我们的图转换器中。具体来说，SHT采用了两层轻量级的图卷积网络

### 2.全局的信息学习

i）通过自适应超图关系学习增强用户协作关系建模来减轻噪声问题； ii）将知识从密集的用户/项目节点转移到稀疏的节点。具体来说，SHT 配置了类似 Transformer 的注意力机制来进行结构学习。编码的图拓扑感知嵌入被注入到节点表示中，以保留图局部性和拓扑位置。iii）通过将 id 对应的嵌入 (ei, ej ) 与拓扑感知嵌入（来自嵌入表 ̄ E(u) 和 ̄ E( 的向量 ̄ e i, ̄ e j ）组合在一起，生成 ui 和 v j 的输入嵌入向量v) ) 

### 3.超边信息传播

SHT 使用 ̃ e i, ̃ e j 作为输入进行基于超图的信息传播以及超图结构学习。我们利用 K 条超边从全球角度提炼协作关系。节点嵌入使用超边作为中间枢纽来相互传播，其中节点和超边之间的连接被优化以反映节点之间的隐式依赖关系。